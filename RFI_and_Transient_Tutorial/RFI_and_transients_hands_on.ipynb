{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/barauna-lo/SAMBATimes/blob/main/RFI_Dection_in_Pulsars.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mj_sYzmj4ynA"
   },
   "source": [
    "# Introdution of the Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7D8Lqnf0414-"
   },
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "xxl_gk6O44vF"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from tqdm import tqdm\n",
    "from scipy.optimize import curve_fit\n",
    "from astropy.time import Time\n",
    "from astropy.timeseries import LombScargle\n",
    "from scipy.signal import periodogram\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#And some useful functions that we will use later\n",
    "def plotSpectrum(spectra,freqs):\n",
    "    plt.plot(freqs,np.average(spectra,axis=0))\n",
    "    plt.xlabel(\"Frequency [GHz]\")\n",
    "    plt.ylabel(\"Counts\")\n",
    "    plt.show()\n",
    "    \n",
    "def plotLC(spectra,periodogram=False,doScatter=False,plotlim=[]):\n",
    "    if len(plotlim)>0:\n",
    "        ind_min=int(plotlim[0]/dt)\n",
    "        ind_max=int(plotlim[1]/dt)\n",
    "    else:\n",
    "        ind_min=0\n",
    "        ind_max=len(spectra)-1\n",
    "        \n",
    "    times=np.linspace(0,(len(spectra)-1)*dt,len(spectra))\n",
    "    times=times[ind_min:ind_max]\n",
    "    intensities=np.nanmean(spectra,axis=1)\n",
    "    intensities=intensities[ind_min:ind_max]\n",
    "    if doScatter:\n",
    "        plt.scatter(times,intensities)\n",
    "    else:\n",
    "        plt.plot(times,intensities)\n",
    "    plt.xlabel(\"Time [s]\")\n",
    "    plt.ylabel(\"Counts\")\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    if periodogram:\n",
    "        freq, p_ls = LombScargle(times, np.nan_to_num(intensities)).autopower(minimum_frequency=0.000000001,\n",
    "                                         maximum_frequency=10,\n",
    "                                         normalization='psd',\n",
    "                                         samples_per_peak=50)\n",
    "        plt.plot(freq,p_ls)\n",
    "        plt.yscale(\"log\")\n",
    "        plt.xlabel(\"Frequency\")\n",
    "        plt.ylabel(\"Spectral Power\")\n",
    "        plt.show()\n",
    "        \n",
    "        return freq, p_ls\n",
    "    \n",
    "    \n",
    "    return times,intensities\n",
    "    \n",
    "def getStokesI(data):\n",
    "    spectra = []\n",
    "    mjds = []\n",
    "    phi=0 #reference angle for Q-U reference frame\n",
    "\n",
    "    #we need to convert the data to total intensity\n",
    "    #since the data are recorded in circular polarization\n",
    "    for i in range(len(data)):\n",
    "        spectrum=[]\n",
    "\n",
    "        mjds.append(data[i][0])\n",
    "\n",
    "        #extract polarization parameters\n",
    "        lcp=np.array(data[i][1][0])\n",
    "        rcp=np.array(data[i][1][1])\n",
    "        COS=np.array(data[i][1][2])\n",
    "        SIN=np.array(data[i][1][3])\n",
    "\n",
    "        I=lcp+rcp\n",
    "        Q=np.cos(phi)*COS-np.sin(phi)*SIN\n",
    "        U=np.sin(phi)*COS+np.cos(phi)*SIN\n",
    "        V=lcp-rcp   \n",
    "\n",
    "\n",
    "        spectra.append(I)#append STOKES I (Q=1,U=2,V=3)\n",
    "\n",
    "    return np.array(spectra)\n",
    "    \n",
    "#Define the Gaussian function\n",
    "def Gauss(x, A, B, C, D):\n",
    "    y = A*np.exp(-1*B*(x-C)**2)+D\n",
    "    return y\n",
    "    \n",
    "#does a simple bandpass calibration by dividing all data by the average spectrum\n",
    "def calibrateBandpass(spectra):\n",
    "    for i in range(len(spectra[0])):\n",
    "        add_count=0\n",
    "        for j in range(len(spectra)):\n",
    "            add_count+=spectra[j][i]\n",
    "        corr_factor=add_count/len(spectra)\n",
    "        for j in range(len(spectra)):\n",
    "            spectra[j][i]=spectra[j][i]/corr_factor\n",
    "            \n",
    "    return spectra\n",
    "\n",
    "def removeNoiseCal(spectra,showPlots=False,removeSource=False):\n",
    "    \n",
    "    #remove noise cal effect \n",
    "    for j in tqdm(range(len(spectra[0]))):\n",
    "\n",
    "        #seperate the two/four phases\n",
    "        bin1=[]\n",
    "        bin2=[]\n",
    "        count=2\n",
    "        switch=True\n",
    "        for i in range(len(spectra)):\n",
    "            if count==0:\n",
    "                switch=not switch \n",
    "                count=2\n",
    "            if switch:\n",
    "                bin1.append(spectra[i][j])\n",
    "            elif not switch:\n",
    "                bin2.append(spectra[i][j])\n",
    "            count-=1\n",
    "\n",
    "        if removeSource:\n",
    "            try:\n",
    "                parameters1, covariance1 = curve_fit(Gauss, np.arange(len(bin1)), np.array(bin1),p0=np.asarray([0.1,1/100,len(bin1)/2,np.average(bin1)]),maxfev = 2000)\n",
    "            except:\n",
    "                parameters1=[0,0,0,0]\n",
    "            try:    \n",
    "                parameters2, covariance2 = curve_fit(Gauss, np.arange(len(bin2)), np.array(bin2),p0=np.asarray([0.1,1/100,len(bin2)/2,np.average(bin2)]),maxfev = 2000)\n",
    "            except:\n",
    "                parameters2=[0,0,0,0]\n",
    "\n",
    "            fit_A1 = parameters1[0]\n",
    "            fit_B1 = parameters1[1]\n",
    "            fit_C1 = parameters1[2]\n",
    "            fit_D1 = parameters1[3]\n",
    "            fit_A2 = parameters2[0]\n",
    "            fit_B2 = parameters2[1]\n",
    "            fit_C2 = parameters2[2]\n",
    "            fit_D2 = parameters2[3]\n",
    "\n",
    "            fit1 = Gauss(np.arange(len(bin1)), fit_A1, fit_B1, fit_C1, fit_D1)\n",
    "            fit2 = Gauss(np.arange(len(bin2)), fit_A2, fit_B2, fit_C2, fit_D2)\n",
    "        else:\n",
    "            fit1 = np.full(len(bin1),np.average(bin1))\n",
    "            fit2 = np.full(len(bin2),np.average(bin2))\n",
    "\n",
    "\n",
    "        if showPlots:\n",
    "            plt.scatter(np.arange(len(bin1)),bin1)\n",
    "            plt.plot(np.arange(len(bin1)),fit1,color=\"yellow\")\n",
    "            plt.scatter(np.arange(len(bin2)),bin2)\n",
    "            plt.plot(np.arange(len(bin2)),fit2,color=\"red\")\n",
    "            plt.show()\n",
    "        \n",
    "        \n",
    "        bin1=bin1-fit1\n",
    "        bin2=bin2-fit2\n",
    "\n",
    "        final_time=[]\n",
    "        i=0\n",
    "        while i<len(bin1):\n",
    "            final_time.append(bin1[i])\n",
    "            if not i+1>=len(bin1):\n",
    "                final_time.append(bin1[i+1])\n",
    "            if not i>=len(bin2):\n",
    "                final_time.append(bin2[i])\n",
    "            if not i+1>=len(bin2):\n",
    "                final_time.append(bin2[i+1])\n",
    "            i+=2\n",
    "\n",
    "\n",
    "        #plt.scatter(np.arange(len(final_time)),final_time)\n",
    "        #plt.show()\n",
    "\n",
    "        for i in range(len(spectra)):\n",
    "            spectra[i][j]=final_time[i]\n",
    "    return spectra\n",
    "\n",
    "#two simple functions for RFI removal (courtesy of H. Shetgaonkar)\n",
    "\n",
    "def get_robust_mean_rms(input_arr, sigma_threshold):\n",
    "    arr = np.copy(input_arr)\n",
    "    ok = False\n",
    "    iter_i, rms, mean = 0, 0.0, 0.0\n",
    "    while not ok:\n",
    "        iter_i += 1\n",
    "        threshold = rms * sigma_threshold\n",
    "\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "            mean = np.nanmean(arr)\n",
    "        rms0 = rms\n",
    "\n",
    "        if iter_i > 1:\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "                arr[abs(arr - mean) > threshold] = np.nan\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "            rms = np.nanstd(arr)\n",
    "\n",
    "        if iter_i > 1:\n",
    "            if rms == 0.0:\n",
    "                ok = True  # return\n",
    "            elif np.isnan(rms):\n",
    "                ok = True\n",
    "            elif abs((rms0 / rms) - 1.0) < 0.01:\n",
    "                ok = True\n",
    "        print(f\"mean={mean} ----> rms={rms}\")\n",
    "    return mean, rms\n",
    "\n",
    "def remove_rfi(dynamic_spectrum, sigma_threshold=3):\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "        mean, rms = np.nanmean(dynamic_spectrum, axis=0), np.nanstd(dynamic_spectrum, axis=0)\n",
    "    \n",
    "    # option for robust mean/rms\n",
    "    snr = 0.5 #float(np.sqrt(1))\n",
    "    efficiency_x = mean / rms * snr\n",
    "    \n",
    "    mean_x, std_x = get_robust_mean_rms(efficiency_x, sigma_threshold)\n",
    "    \n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "        flagged_ds = np.where(abs(mean_x - efficiency_x) > sigma_threshold * std_x, np.nan, dynamic_spectrum)\n",
    "\n",
    "    return flagged_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ix2V4cbk56EF"
   },
   "source": [
    "## Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BSqD0A5f4tKo",
    "outputId": "2b23524e-7b7b-490d-b8e9-e45e1c267bda"
   },
   "outputs": [],
   "source": [
    "#Effelsberg data TELAMON\n",
    "filename = \"S20mm-SPECPOL-ARRAYDATA-1.fits\"\n",
    "telamon_data_fits = fits.open(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XaJv69H051Zt"
   },
   "source": [
    "## Let's inspect the data - See all the informations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "_X2B_JeC50l7"
   },
   "outputs": [],
   "source": [
    "#View FITS tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#The data are stored in Table 1, so let's inspect that further and view the header info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's extract some important information\n",
    "scantime = 28 #scantime in seconds (not included in header)\n",
    "bandwidth =\n",
    "center_freq =\n",
    "low_freq=\n",
    "high_freq=\n",
    "\n",
    "#and read out the data\n",
    "data = \n",
    "#convert data from circular Polarization to StokesI (use getStokesI(data))\n",
    "spectra = \n",
    "\n",
    "#extract some information\n",
    "dt=\n",
    "freqs="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dM6X9dOH5SG2"
   },
   "source": [
    "## Data Vizualization & Basic Calibration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Y1heKuva5RLn"
   },
   "outputs": [],
   "source": [
    "# Now that we have imported the data, let's plot it\n",
    "# First, let's start with a simple waterfall/imshow plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's also look at the spectrum summed over time (use plotSpectrum(spectra,freqs))\n",
    "\n",
    "\n",
    "#We need to correct for the bandpass (different sensitivy for different frequencies), let's do this with calibrateBandpass(spectra)\n",
    "\n",
    "spectra=\n",
    "#Now plot again the spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#And the \"lightcurve\", summed over all frequencies can be plotted with plotLC(spectra)\n",
    "\n",
    "#We have to remove a Noise Diode effect from the data, this can be done with removeNoiseCal(spectra)\n",
    "\n",
    "#Now look at the lightcurve again to see the change\n",
    "\n",
    "#And we can also remove the Blazar Target since we are not interested in it for this project (we are looking for transients!)\n",
    "#To do this, we use removeNoiseCal(spectra,removeSource=True)\n",
    "\n",
    "#Now look at the light curve again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's shift it to counts>0\n",
    "\n",
    "\n",
    "#Let's look at the waterfaller/imshow plot again\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hqkRNkQy5m5S"
   },
   "source": [
    "# Clean RFI in the charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "zkr0cSbS5FGP"
   },
   "outputs": [],
   "source": [
    "# Let's try to get rid of the most prominent RFI components and clean the scan\n",
    "# First, let's try a simple manual flagging where we exclude the brightest visible RFI channel\n",
    "mask=np.zeros(spectra.shape)\n",
    "mask[:,130:140]=1\n",
    "spectra_masked=np.ma.masked_array(spectra,mask)\n",
    "\n",
    "#Let's plot the LC again and the spectrum to see what changed\n",
    "\n",
    "\n",
    "#Waterfall plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Still we see a lot of RFI-like signals, let's see if we can get rid of more of them if we put more masks\n",
    "\n",
    "#plot lightcurve and spectrum again\n",
    "\n",
    "#Waterfall plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looks better but still not perfect, for instance if we zoom in a bit, we see there is still a lot of RFI signal\n",
    "#-> all of this is quite tedious to get rid of manually, so we need some more powerful tools!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's try a bit more sophisticated RFI removal using the functions introduced at the beginning \n",
    "#rms based flagging (remove_rfi(spectra))\n",
    "\n",
    "#and plot lightcurve and spectrum\n",
    "\n",
    "\n",
    "#Waterfall plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5iwlhzI35sUG"
   },
   "source": [
    "# Let's look at some UIRAPURU data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "cUms_O4q5uPY"
   },
   "outputs": [],
   "source": [
    "#UIRAPURU data \n",
    "filename = \"UIRAPURU_20230203_082000_59.fit\"\n",
    "uirapuru_data_fits = fits.open(filename)\n",
    "\n",
    "#View FITS tables\n",
    "\n",
    "\n",
    "#View Header Info\n",
    "header=\n",
    "\n",
    "#read out some basic information\n",
    "date_obs=header[\"DATE-OBS\"].replace(\"/\",\"-\")+\"T\"+header[\"TIME-OBS\"]\n",
    "date_end=header[\"DATE-END\"].replace(\"/\",\"-\")+\"T\"+header[\"TIME-END\"]\n",
    "scantime=Time(date_end)-Time(date_obs)\n",
    "scantime=scantime.sec #get scantime in seconds\n",
    "dt=scantime/float(header[\"NAXIS1\"])\n",
    "\n",
    "header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#let's try with a fake transient -> we play with this later\\nimage_data[500:510,100:200]=image_data[500:510,100:200]+2\\n\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_data=np.transpose(uirapuru_data_fits[0].data)\n",
    "\n",
    "\"\"\"\n",
    "#let's try with a fake transient -> we play with this later\n",
    "image_data[500:510,100:200]=image_data[500:510,100:200]+2\n",
    "\"\"\"\n",
    "\n",
    "#do waterfall plot\n",
    "\n",
    "#plot spectrum and lightcurve\n",
    "plotLC(image_data)\n",
    "plotSpectrum(image_data,np.linspace(0.98,1.26,len(image_data[0])))\n",
    "\n",
    "#try a bandpass calibration\n",
    "\n",
    "\n",
    "#plot spectrum, lightcurve and waterfall again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can see, here it is quite challenging to recover any sensible data because of the complex RFI environment\n",
    "#let's try with automatic rfi flagging...(remove_rfi(...))\n",
    "cleaned_spectra=\n",
    "\n",
    "#and plot lightcurve and spectrum\n",
    "\n",
    "#Waterfall plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Effelsberg Data with a real astrophysical signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Effelsberg data TELAMON with Pulsar Data\n",
    "filename = \"S45mm-SPECPOL-ARRAYDATA-1.fits\"\n",
    "telamon_data_fits = fits.open(filename)\n",
    "\n",
    "#extract info like before\n",
    "\n",
    "\n",
    "#and read out the data\n",
    "\n",
    "#convert data from circular Polarization to StokesI\n",
    "\n",
    "\n",
    "#extract some information\n",
    "\n",
    "\n",
    "# Now that we have imported the data, let's plot it\n",
    "# First, let's start with a simple waterfall plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Let's do all the preliminary calibration steps we learned about before\n",
    "\n",
    "#Calibrate the Bandpass\n",
    "\n",
    "\n",
    "#Remove Noisecal\n",
    "\n",
    "\n",
    "#shift spectrum to positive values\n",
    "#let's shift it to counts>0\n",
    "\n",
    "\n",
    "#Now plot again the Waterfaller "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets try some manual masking (try out different options)\n",
    "\n",
    "\n",
    "#or lets try some automatic flagging\n",
    "\n",
    "\n",
    "#Now plot again the Waterfaller "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#It's not perfect yet but now we can look at the Light Curve again between 10 and 20s (plotlim argument)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "## Now let's take a look at a periodogram to identify the period of the pulsar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HsyXQQ2k7AcI"
   },
   "source": [
    "# How can we generalize this and detect not only periodic events but also transients (FRBs)?\n",
    "There are a lot of pulsar analysis packages (mostly C-based) which use sophisticated algorhithms to tackle all of these problems. \n",
    "\n",
    "If we have time we can look at some of these programs in a virtual machine:\n",
    "- PRESTO\n",
    "- TransientX\n",
    "\n",
    "Possible problems for the data sets we looked at today:\n",
    "- different data formats -> need to convert the fits files to PSRFITS standard or filterbank files\n",
    "- very bad time sampling in TELAMON and UIRAPURU data: usually pulsar data comes in much better time- (and frequency-) resolution, therefore some methods from the pulsar world might not be applicable to the data sets we looked at today!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6YM5o57f7Jp1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOpFoqXhrgssolUPl9ZA4L/",
   "include_colab_link": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
